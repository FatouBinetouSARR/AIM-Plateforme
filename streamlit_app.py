# ================================================================
# streamlit_app.py ‚Äî Version compl√®te avec toutes les fonctionnalit√©s
# AIM : Analyse Marketing Intelligente
# ================================================================

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import re
import plotly.express as px
import plotly.graph_objects as go
from collections import Counter
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
import requests
from datetime import datetime, timedelta

# ================================================================
# üé® Palette couleurs AIM + Fond jaune clair
# ================================================================
AIM_PALETTE = [
    "#2ECC71", "#27AE60", "#3498DB", "#2980B9",
    "#F1C40F", "#F39C12", "#E67E22", "#E74C3C", "#C0392B"
]

# Configuration du fond jaune tr√®s clair
BACKGROUND_COLOR = "#FFFDE7"  # Jaune tr√®s clair et lumineux
SIDEBAR_COLOR = "#FFF9C4"    # Jaune un peu plus soutenu pour le sidebar
TEXT_COLOR = "#212121"       # Gris fonc√© pour meilleur contraste

# Appliquer le style CSS pour le fond clair et titre centr√©
page_bg_css = """
<style>
.stApp {
    background-color: #FFFDE7 !important;
    color: #212121 !important;
}

/* TITRE PRINCIPAL CENTR√â ET PLUS GROS */
h1 {
    text-align: center !important;
    font-size: 3.5rem !important;
    font-weight: 800 !important;
    color: #FF6B00 !important;
    margin-top: 20px !important;
    margin-bottom: 40px !important;
    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);
    background: linear-gradient(90deg, #FF6B00, #FF9800);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    padding: 15px;
    border-bottom: 4px solid #FFD54F;
}

/* Sous-titres */
h2 {
    font-size: 2.2rem !important;
    font-weight: 700 !important;
    color: #5D4037 !important;
    margin-top: 30px !important;
    margin-bottom: 20px !important;
    padding-bottom: 10px;
    border-bottom: 2px solid #FFD54F;
}

h3 {
    font-size: 1.8rem !important;
    font-weight: 600 !important;
    color: #795548 !important;
}

/* Style pour les cartes d'opportunit√©s */
.opportunity-card {
    background: linear-gradient(135deg, #ffffff, #FFF9C4);
    border-radius: 15px;
    padding: 20px;
    margin: 15px 0;
    border-left: 6px solid #FF9800;
    box-shadow: 0 6px 15px rgba(0, 0, 0, 0.08);
    transition: transform 0.3s ease, box-shadow 0.3s ease;
}

.opportunity-card:hover {
    transform: translateY(-5px);
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.12);
}

.opportunity-badge {
    display: inline-block;
    background: linear-gradient(90deg, #FF9800, #FF5722);
    color: white;
    padding: 8px 15px;
    border-radius: 20px;
    font-weight: bold;
    margin-bottom: 10px;
    font-size: 0.9rem;
}

.opportunity-tag {
    display: inline-block;
    background: #E3F2FD;
    color: #1565C0;
    padding: 5px 12px;
    border-radius: 15px;
    margin: 3px;
    font-size: 0.85rem;
    border: 1px solid #90CAF9;
}

/* Style pour le contenu principal */
.main .block-container {
    background-color: rgba(255, 255, 255, 0.85) !important;
    border-radius: 15px;
    padding: 25px;
    margin-top: 20px;
    margin-bottom: 20px;
    box-shadow: 0 8px 20px rgba(0, 0, 0, 0.08);
    border: 1px solid rgba(255, 235, 59, 0.2);
}

/* Style pour les cartes et sections */
.css-1d391kg, .css-12oz5g7, .css-1y4p8pa, .css-18e3th9, .css-1lcbmhc {
    background-color: rgba(255, 255, 255, 0.92) !important;
    border-radius: 12px;
    padding: 20px;
    margin-bottom: 15px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
    border: 1px solid rgba(255, 235, 59, 0.3);
}

/* Style pour les m√©triques */
.css-1xarl3l, .css-1v0mbdj, [data-testid="stMetric"] {
    background-color: rgba(255, 255, 255, 0.95) !important;
    border-radius: 10px;
    padding: 15px;
    border: 2px solid #FFEB3B !important;
    box-shadow: 0 3px 8px rgba(255, 193, 7, 0.15);
}

/* Style pour le sidebar */
.css-1d391kg {
    background-color: rgba(255, 253, 231, 0.95) !important;
}

/* Style pour les faux avis */
.fake-review-card {
    background: linear-gradient(135deg, #FFEBEE, #FFCDD2);
    border-radius: 10px;
    padding: 15px;
    margin: 10px 0;
    border-left: 6px solid #F44336;
    box-shadow: 0 4px 10px rgba(244, 67, 54, 0.1);
}

.real-review-card {
    background: linear-gradient(135deg, #E8F5E9, #C8E6C9);
    border-radius: 10px;
    padding: 15px;
    margin: 10px 0;
    border-left: 6px solid #4CAF50;
    box-shadow: 0 4px 10px rgba(76, 175, 80, 0.1);
}

/* Style pour les statistiques */
.statistics-table {
    background: white;
    border-radius: 10px;
    padding: 15px;
    margin: 15px 0;
    box-shadow: 0 3px 10px rgba(0,0,0,0.1);
}
</style>
"""

# ================================================================
# ‚öôÔ∏è Configuration Streamlit
# ================================================================
st.set_page_config(page_title="AIM ‚Äì Dashboard", page_icon="üìä", layout="wide")
st.markdown(page_bg_css, unsafe_allow_html=True)

# TITRE CENTR√â AVEC MARKDOWN POUR UN MEILLUR CONTR√îLE
st.markdown("""
<div style="text-align: center;">
    <h1 style="font-size: 3.8rem; font-weight: 900; color: #FF6B00; 
               margin-bottom: 10px; text-shadow: 3px 3px 6px rgba(0,0,0,0.15);">
        üìä AIM ‚Äì Analyse Marketing Intelligente
    </h1>
    <p style="font-size: 1.3rem; color: #666; margin-top: 0; margin-bottom: 40px;">
        Plateforme d'analyse avanc√©e des sentiments, d√©tection de faux avis et insights marketing
    </p>
</div>
""", unsafe_allow_html=True)

# ================================================================
# üîß Fonctions utilitaires
# ================================================================
@st.cache_data(show_spinner=False)
def safe_load(filename):
    try:
        return joblib.load(filename)
    except:
        return None

def clean_text(text):
    if pd.isnull(text):
        return ""
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+|https\S+", " ", text)
    text = re.sub(r"[^a-z0-9√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ß\s]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def detect_fake_reviews(texts, threshold=0.6):
    """D√©tection de faux avis par patterns et analyse linguistique"""
    fake_patterns = [
        # Patterns de r√©p√©tition exag√©r√©e
        r"(excellent|parfait|g√©nial|incroyable).{0,5}\1",
        r"(\w+).{0,3}\1.{0,3}\1",  # Mots r√©p√©t√©s 3 fois
        
        # Patterns de formules g√©n√©riques
        r"je.*recommande.*(√† tous|fortement|vivement)",
        r"produit.*(exceptionnel|parfait|incroyable).*service.*(exceptionnel|parfait|incroyable)",
        
        # Patterns de superlatifs multiples
        r"(tr√®s|vraiment|absolument).{0,5}(bon|excellent|parfait|g√©nial)",
        r"(le|la).{0,5}(meilleur|meilleure|top|num√©ro)",
        
        # Patterns de spam
        r"ach.{0,5}maintenant|commander.{0,5}imm√©diat",
        r"\d{5,}|[A-Z]{5,}",  # Codes ou s√©ries de majuscules
        
        # Patterns de manque de sp√©cificit√©
        r"produit|service|article.{0,10}(correct|ok|bien)",
    ]
    
    fake_scores = []
    fake_reasons = []
    
    for text in texts:
        score = 0
        reasons = []
        
        # V√©rifier chaque pattern
        for i, pattern in enumerate(fake_patterns):
            if re.search(pattern, text, re.IGNORECASE):
                score += 0.1
                reasons.append(f"Pattern {i+1}")
        
        # Longueur du texte (trop court = suspect)
        if len(text.split()) < 5:
            score += 0.3
            reasons.append("Texte trop court")
        
        # √âmojis excessifs
        emoji_count = len(re.findall(r'[^\w\s,]', text))
        if emoji_count > 5:
            score += 0.2
            reasons.append("Trop d'√©mojis")
        
        fake_scores.append(score / 1.0)  # Normalisation
        fake_reasons.append(", ".join(reasons[:3]) if reasons else "Aucun pattern d√©tect√©")
    
    # D√©terminer si c'est faux bas√© sur le seuil
    is_fake = [score > threshold for score in fake_scores]
    
    return is_fake, fake_scores, fake_reasons

def calculate_engagement_score(df, product_col=None):
    """Calcul du score d'engagement"""
    engagement_scores = []
    
    for idx, row in df.iterrows():
        score = 0
        
        # Score bas√© sur la longueur du texte
        text_length = len(str(row.get('clean_text', '')))
        if text_length > 100:
            score += 2
        elif text_length > 50:
            score += 1
        
        # Score bas√© sur le sentiment
        sentiment = row.get('sentiment', 'neutral')
        if sentiment == 'positive':
            score += 2
        elif sentiment == 'negative':
            score += 1  # Les avis n√©gatifs montrent aussi de l'engagement
        
        # Score bas√© sur la pr√©sence de questions
        if '?' in str(row.get('clean_text', '')):
            score += 1
        
        # Score bas√© sur la pr√©sence de mots d'action
        action_words = ['recommand', 'ach√®terai', 'conseill', 'utilis', 'essay']
        text_lower = str(row.get('clean_text', '')).lower()
        if any(word in text_lower for word in action_words):
            score += 1
        
        engagement_scores.append(min(score, 5))  # Limiter √† 5
    
    return engagement_scores

def fetch_from_api(api_url, api_key=None, params=None):
    """Fonction pour r√©cup√©rer des donn√©es depuis une API"""
    try:
        headers = {"Authorization": f"Bearer {api_key}"} if api_key else {}
        if params is None:
            params = {}
        
        response = requests.get(api_url, headers=headers, params=params, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            
            # Convertir en DataFrame (structure g√©n√©rique)
            if isinstance(data, list):
                df = pd.DataFrame(data)
            elif isinstance(data, dict):
                if 'data' in data:
                    df = pd.DataFrame(data['data'])
                elif 'results' in data:
                    df = pd.DataFrame(data['results'])
                else:
                    # Essayer de cr√©er un DataFrame avec le dictionnaire
                    df = pd.DataFrame([data])
            else:
                df = pd.DataFrame()
            
            return df
        else:
            st.error(f"Erreur API: {response.status_code}")
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"Erreur de connexion √† l'API: {e}")
        return pd.DataFrame()

# ================================================================
# üì• IMPORTATION DES DONN√âES
# ================================================================
st.sidebar.header("üì• Source des donn√©es")

# Initialisation de la variable session state pour stocker les donn√©es
if 'df' not in st.session_state:
    st.session_state.df = None
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False

# Choix de la source
data_source = st.sidebar.radio("Choisir la source:", ["Fichier local", "API Entreprise", "Exemple de donn√©es"])

if data_source == "Fichier local":
    st.sidebar.header("1Ô∏è‚É£ Importer un Dataset")
    uploaded = st.sidebar.file_uploader("Importer un CSV ou Excel", type=["csv", "xlsx"])
    
    if uploaded is not None:
        try:
            if uploaded.name.lower().endswith(".csv"):
                st.session_state.df = pd.read_csv(uploaded)
            else:
                st.session_state.df = pd.read_excel(uploaded)
            st.session_state.data_loaded = True
            st.sidebar.success(f"‚úÖ {uploaded.name} charg√© avec succ√®s !")
        except Exception as e:
            st.sidebar.error(f"‚ùå Erreur lors du chargement : {e}")
            st.stop()
    else:
        if not st.session_state.data_loaded:
            st.info("üóÇÔ∏è Veuillez importer un fichier pour commencer.")
            st.stop()

elif data_source == "API Entreprise":
    st.sidebar.header("üåê Connexion API")
    
    api_url = st.sidebar.text_input("URL de l'API", value="https://api.example.com/reviews")
    api_key = st.sidebar.text_input("Cl√© API", type="password")
    
    # Param√®tres API
    col1, col2 = st.sidebar.columns(2)
    with col1:
        limit = st.number_input("Nombre de r√©sultats", min_value=10, max_value=1000, value=100)
    with col2:
        days_back = st.number_input("Derniers jours", min_value=1, max_value=365, value=30)
    
    # Bouton pour r√©cup√©rer les donn√©es
    if st.sidebar.button("üì° R√©cup√©rer les donn√©es", type="primary"):
        with st.spinner("Connexion √† l'API en cours..."):
            params = {
                'limit': limit,
                'date_from': (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
            }
            df_temp = fetch_from_api(api_url, api_key, params)
            
            if df_temp is not None and not df_temp.empty:
                st.session_state.df = df_temp
                st.session_state.data_loaded = True
                st.sidebar.success(f"‚úÖ {len(df_temp)} enregistrements r√©cup√©r√©s")
            else:
                st.sidebar.warning("‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e ou erreur de connexion")
                st.stop()
    
    # Si aucune donn√©e n'a √©t√© charg√©e, afficher un message
    if not st.session_state.data_loaded:
        st.info("üåê Configurez les param√®tres de l'API et cliquez sur 'R√©cup√©rer les donn√©es'")
        st.stop()

elif data_source == "Exemple de donn√©es":
    # Cr√©er un dataset exemple plus complet et vari√©
    st.sidebar.info("üìä Chargement des donn√©es exemple...")
    
    example_data = {
        'produit': ['iPhone 15 Pro', 'iPhone 15 Pro', 'Samsung Galaxy S24', 'Samsung Galaxy S24', 'Google Pixel 8', 
                   'iPhone 15 Pro', 'Samsung Galaxy S24', 'Google Pixel 8', 'iPhone 15 Pro', 'Google Pixel 8',
                   'Casque Sony WH-1000XM5', 'MacBook Pro M3', 'Nike Air Max', 'PlayStation 5', 'Canon EOS R5'],
        'avis': [
            'Le t√©l√©phone est excellent, la cam√©ra est incroyable pour les photos de nuit.',
            'Bonne batterie, √©cran fluide. Je suis satisfait de mon achat.',
            'Correct mais la batterie se d√©charge trop vite. Rien d exceptionnel.',
            'Incroyable ! Le meilleur t√©l√©phone Android ! ACHETEZ-LE MAINTENANT !',
            'Service client m√©diocre mais le produit fonctionne bien.',
            'Bon rapport qualit√©-prix, je recommande ce produit √† mes amis.',
            'Mauvais produit, je regrette mon achat. La qualit√© est faible.',
            'Photos exceptionnelles, interface intuitive. Tr√®s bon t√©l√©phone.',
            'Correct mais pourrait √™tre am√©lior√©. La charge rapide manque.',
            'PARFAIT PARFAIT PARFAIT ! Meilleur achat de l ann√©e !',
            'Casque confortable, r√©duction de bruit impressionnante. Excellent achat.',
            'Ordinateur puissant, √©cran Retina magnifique. Parfait pour le travail.',
            'Chaussures tr√®s confortables pour la course. Je les utilise tous les jours.',
            'Console g√©niale, les graphismes sont incroyables. Je recommande !',
            'Appareil photo professionnel, autofocus rapide. Id√©al pour les portraits.'
        ],
        'date': pd.date_range(start='2024-01-01', periods=15, freq='D'),
        'note': [5, 4, 3, 5, 2, 4, 1, 5, 3, 5, 5, 5, 4, 5, 5],
        'utilisateur': ['JeanDupont', 'MarieMartin', 'PierreDurand', 'SophieLeroy', 'ThomasMoreau',
                       'JulieBernard', 'NicolasPetit', 'IsabelleRoux', 'MichelLefevre', 'CarolineMorel',
                       'DavidSimon', 'SarahLaurent', 'AlexandreFontaine', 'LauraChevalier', 'MarcDumont']
    }
    
    st.session_state.df = pd.DataFrame(example_data)
    st.session_state.data_loaded = True
    st.sidebar.success("‚úÖ Donn√©es exemple charg√©es")

# V√©rifier si le DataFrame est vide ou None
if st.session_state.df is None or st.session_state.df.empty or not st.session_state.data_loaded:
    st.warning("‚ö†Ô∏è Aucune donn√©e disponible. Veuillez charger des donn√©es.")
    st.stop()

# R√©cup√©rer le DataFrame depuis session state
df = st.session_state.df


# ================================================================
# üîç FILTRES AVANC√âS
# ================================================================
st.sidebar.header("üîç Filtres Avanc√©s")

# Identifier les colonnes potentielles pour les filtres
# Version robuste qui n'utilise pas select_dtypes
text_columns = []
date_columns = []
numeric_columns = []

if df is not None and not df.empty:
    for col in df.columns:
        try:
            # V√©rifier le type de la colonne
            col_dtype = str(df[col].dtype)
            
            # D√©tecter les colonnes texte
            if any(dtype in col_dtype.lower() for dtype in ['object', 'string', 'category']):
                text_columns.append(col)
            # V√©rifier si c'est une colonne datetime
            elif any(dtype in col_dtype.lower() for dtype in ['datetime', 'date', 'time']):
                date_columns.append(col)
            # V√©rifier si c'est num√©rique
            elif any(dtype in col_dtype.lower() for dtype in ['int', 'float', 'number']):
                numeric_columns.append(col)
            # Fallback : v√©rifier le contenu
            else:
                # √âchantillonner quelques valeurs
                sample = df[col].dropna().head(5)
                if len(sample) > 0:
                    # V√©rifier si c'est du texte
                    if all(isinstance(x, str) for x in sample):
                        text_columns.append(col)
                    # V√©rifier si c'est une date
                    elif all(isinstance(x, (datetime, pd.Timestamp)) for x in sample):
                        date_columns.append(col)
                    # V√©rifier si c'est num√©rique
                    elif all(isinstance(x, (int, float, np.number)) for x in sample):
                        numeric_columns.append(col)
        except:
            continue
else:
    st.sidebar.warning("‚ö†Ô∏è Aucune donn√©e disponible pour les filtres")

# Filtre par colonne de texte (si disponible)
if text_columns:
    search_column = st.sidebar.selectbox("Colonne √† rechercher:", text_columns)
    keyword = st.sidebar.text_input("Rechercher un mot-cl√©")
else:
    keyword = ""
    search_column = None

# Filtre par date (si disponible)
if date_columns:
    date_column = st.sidebar.selectbox("Colonne de date:", date_columns)
    if df[date_column].notna().any():
        min_date = df[date_column].min()
        max_date = df[date_column].max()
        date_range = st.sidebar.date_input(
            "P√©riode:",
            value=[min_date, max_date],
            min_value=min_date,
            max_value=max_date
        )
    else:
        date_range = None
else:
    date_range = None

# Filtre par note (si disponible)
rating_filter = None
if 'note' in df.columns or 'rating' in df.columns:
    rating_col = 'note' if 'note' in df.columns else 'rating'
    if df[rating_col].notna().any():
        min_rating = int(df[rating_col].min())
        max_rating = int(df[rating_col].max())
        rating_range = st.sidebar.slider(
            "Filtrer par note:",
            min_value=min_rating,
            max_value=max_rating,
            value=(min_rating, max_rating)
        )
        rating_filter = rating_range

# Appliquer les filtres
filtered_df = df.copy()

if keyword and search_column:
    filtered_df = filtered_df[filtered_df[search_column].str.contains(keyword, case=False, na=False)]

if date_range and len(date_range) == 2 and date_columns:
    filtered_df = filtered_df[
        (filtered_df[date_column] >= pd.Timestamp(date_range[0])) &
        (filtered_df[date_column] <= pd.Timestamp(date_range[1]))
    ]

if rating_filter:
    filtered_df = filtered_df[
        (filtered_df[rating_col] >= rating_filter[0]) &
        (filtered_df[rating_col] <= rating_filter[1])
    ]

# Afficher le nombre de r√©sultats filtr√©s
st.sidebar.metric("R√©sultats filtr√©s", len(filtered_df))

# ================================================================
# üìå APER√áU DU DATASET
# ================================================================
st.subheader("üìå Aper√ßu du dataset")

# V√©rifier si filtered_df n'est pas vide
if filtered_df.empty:
    st.warning("‚ö†Ô∏è Aucune donn√©e ne correspond aux filtres appliqu√©s. Veuillez ajuster vos crit√®res de filtrage.")
    st.stop()

# Calculer le pourcentage de donn√©es filtr√©es en √©vitant la division par z√©ro
if len(df) > 0:
    filtered_percentage = len(filtered_df) / len(df)
else:
    filtered_percentage = 0

st.write(f"Nombre de lignes : **{filtered_df.shape[0]}** (filtr√©: {filtered_percentage:.0%} du total)")
st.write(f"Nombre de colonnes : **{filtered_df.shape[1]}**")

with st.expander("Voir les premi√®res lignes"):
    st.dataframe(filtered_df.head(), use_container_width=True)

with st.expander("Voir les statistiques descriptives"):
    if not filtered_df.empty:
        st.write(filtered_df.describe())
    else:
        st.write("Aucune statistique disponible.")

# ================================================================
# üßπ PR√âTRAITEMENT AUTOMATIQUE DU TEXTE
# ================================================================
st.subheader("üßπ Pr√©traitement automatique du texte")

# Identifier les colonnes texte de mani√®re robuste
text_cols = []
if filtered_df is not None and not filtered_df.empty:
    for col in filtered_df.columns:
        try:
            # V√©rifier si la colonne contient du texte
            sample = filtered_df[col].dropna().head(5)
            if len(sample) > 0:
                # V√©rifier si au moins une valeur est une string
                if any(isinstance(x, str) for x in sample):
                    text_cols.append(col)
        except:
            continue

if len(text_cols) == 0:
    st.error("‚ùå Aucune colonne texte trouv√©e dans les donn√©es filtr√©es.")
    st.write("**Conseil :** V√©rifiez que votre dataset contient des colonnes avec du texte (commentaires, avis, descriptions, etc.)")
    st.stop()

st.info(f"üîç Colonnes texte d√©tect√©es : {', '.join(text_cols[:3])}{'...' if len(text_cols) > 3 else ''}")

# Nettoyer chaque colonne texte
for col in text_cols:
    filtered_df[col] = filtered_df[col].astype(str).apply(clean_text)

# Combiner toutes les colonnes texte en une seule
filtered_df["clean_text"] = filtered_df[text_cols].agg(" ".join, axis=1)

# V√©rifier que le texte nettoy√© n'est pas vide
if filtered_df["clean_text"].str.len().sum() == 0:
    st.warning("‚ö†Ô∏è Le texte nettoy√© est vide. V√©rifiez le contenu de vos donn√©es.")
else:
    st.success(f"‚úÖ Texte nettoy√© avec succ√®s ({len(text_cols)} colonnes trait√©es)")

# ================================================================
# üïµÔ∏è D√âTECTION DES FAUX AVIS
# ================================================================
st.header("üïµÔ∏è D√©tection des Faux Avis")

# Ajouter un contr√¥le pour ajuster le seuil de d√©tection
col_thresh1, col_thresh2 = st.columns([1, 3])
with col_thresh1:
    detection_threshold = st.slider(
        "Seuil de d√©tection", 
        min_value=0.1, 
        max_value=1.0, 
        value=0.6,
        step=0.05,
        help="Ajustez la sensibilit√© de d√©tection des faux avis. Valeur plus basse = plus sensible."
    )

with col_thresh2:
    st.info(f"""
    **Param√®tre actuel : {detection_threshold}**
    - **< 0.4** : Tr√®s sensible (d√©tecte plus de faux avis)
    - **0.4-0.7** : √âquilibre recommand√©
    - **> 0.7** : Moins sensible (faux positifs r√©duits)
    """)

with st.spinner("Analyse des patterns suspects..."):
    is_fake, fake_scores, fake_reasons = detect_fake_reviews(
        filtered_df["clean_text"].tolist(), 
        threshold=detection_threshold  # Utiliser le seuil dynamique
    )
    filtered_df["is_fake"] = is_fake
    filtered_df["fake_score"] = fake_scores
    filtered_df["fake_reason"] = fake_reasons

# KPI de d√©tection des faux avis (DOIT √äTRE APR√àS LA D√âTECTION DYNAMIQUE)
fake_count = filtered_df["is_fake"].sum()
real_count = len(filtered_df) - fake_count
fake_percentage = fake_count / len(filtered_df) if len(filtered_df) > 0 else 0

col1, col2, col3, col4 = st.columns(4)
col1.metric("Total avis", len(filtered_df))
col2.metric("Faux avis", fake_count, f"{fake_percentage:.1%}")
col3.metric("Avis authentiques", real_count)
col4.metric("Score de confiance", f"{(1 - fake_percentage)*100:.1f}%")

# Afficher quelques exemples (DOIT √äTRE APR√àS LES KPI)
st.subheader("üîç Exemples d'analyse")

# R√©cup√©rer les exemples APRES la d√©tection dynamique
fake_examples = filtered_df[filtered_df["is_fake"]].head(3)
real_examples = filtered_df[~filtered_df["is_fake"]].head(3)

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ‚ö†Ô∏è Avis suspects d√©tect√©s")
    if not fake_examples.empty:
        for idx, row in fake_examples.iterrows():
            # R√©cup√©rer le texte original (avant nettoyage)
            original_text = row.get('avis', row.get('review', 'Texte non disponible'))
            
            # D√©terminer le niveau de risque bas√© sur le score
            fake_score = row['fake_score']
            if fake_score >= 0.8:
                risk_level = "üü• HAUT RISQUE"
                risk_color = "#C0392B"
            elif fake_score >= 0.6:
                risk_level = "üüß RISQUE MOD√âR√â"
                risk_color = "#E67E22"
            else:
                risk_level = "üü® FAIBLE RISQUE"
                risk_color = "#F1C40F"
            
            # Formater la note
            rating = row.get('note', row.get('rating', 'N/A'))
            if isinstance(rating, (int, float)) and rating <= 5:
                rating_display = f"{rating}/5"
            else:
                rating_display = str(rating)
            
            st.markdown(f"""
            <div class="fake-review-card">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                    <strong style="color: {risk_color}; font-size: 1.1rem;">
                        {risk_level}
                    </strong>
                    <span style="background: {risk_color}; color: white; padding: 3px 8px; border-radius: 12px; font-size: 0.9rem;">
                        Score: {fake_score:.2f}/1.0
                    </span>
                </div>
                <div style="margin-bottom: 10px;">
                    <strong>üîç Raisons:</strong> {row['fake_reason']}
                </div>
                <div style="margin-bottom: 10px;">
                    <strong>üìù Avis suspect:</strong> {original_text[:200]}{'...' if len(original_text) > 200 else ''}
                </div>
                <div style="display: flex; justify-content: space-between; flex-wrap: wrap; gap: 10px; font-size: 0.9rem;">
                    <div>
                        <strong>üë§</strong> {row.get('utilisateur', row.get('user', 'Anonyme'))}
                    </div>
                    <div>
                        <strong>‚≠ê</strong> {rating_display}
                    </div>
                    <div>
                        <strong>üìÖ</strong> {row.get('date', 'Date non disponible')}
                    </div>
                </div>
                <div style="margin-top: 10px; font-size: 0.85rem; color: #666;">
                    <strong>üí° Analyse:</strong> Cet avis pr√©sente {len(row['fake_reason'].split(', '))} caract√©ristiques suspectes.
                </div>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.success("""
        ‚úÖ **Excellent ! Aucun faux avis d√©tect√©**
        
        **Vos donn√©es semblent authentiques :**
        - Tous les avis analys√©s paraissent l√©gitimes
        - Aucun pattern suspect n'a √©t√© identifi√©
        - Score de confiance global √©lev√©
        
        **üí° Recommandation :** Continuez √† surveiller r√©guli√®rement vos avis pour maintenir cette qualit√©.
        """)

with col2:
    st.markdown("#### ‚úÖ Avis authentiques")
    if not real_examples.empty:
        for idx, row in real_examples.iterrows():
            # R√©cup√©rer le texte original (avant nettoyage)
            original_text = row.get('avis', row.get('review', 'Texte non disponible'))
            
            # D√©terminer le score de confiance (en pourcentage)
            confidence_score = (1 - row['fake_score']) * 100
            
            # D√©terminer la couleur bas√©e sur le score de confiance
            if confidence_score >= 80:
                confidence_color = "#2ECC71"  # Vert
                confidence_text = "√âlev√©"
            elif confidence_score >= 60:
                confidence_color = "#F1C40F"  # Jaune
                confidence_text = "Moyen"
            else:
                confidence_color = "#E67E22"  # Orange
                confidence_text = "Faible"
            
            # Formater la note
            rating = row.get('note', row.get('rating', 'N/A'))
            if isinstance(rating, (int, float)) and rating <= 5:
                rating_stars = "‚≠ê" * int(rating)
                rating_display = f"{rating}/5 {rating_stars}"
            else:
                rating_display = str(rating)
            
            # Formater la date si disponible
            date_value = row.get('date', '')
            if pd.notna(date_value):
                if isinstance(date_value, (datetime, pd.Timestamp)):
                    formatted_date = date_value.strftime("%d/%m/%Y")
                else:
                    formatted_date = str(date_value)[:10]
            else:
                formatted_date = "Non disponible"
            
            st.markdown(f"""
            <div class="real-review-card">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                    <strong style="color: {confidence_color}; font-size: 1.1rem;">
                        üõ°Ô∏è Confiance: {confidence_text} ({confidence_score:.0f}%)
                    </strong>
                    <span style="background: {confidence_color}; color: white; padding: 3px 8px; border-radius: 12px; font-size: 0.8rem;">
                        {row['fake_score']:.2f}/1.0
                    </span>
                </div>
                <div style="margin-bottom: 10px;">
                    <strong>üìù Avis:</strong> {original_text[:200]}{'...' if len(original_text) > 200 else ''}
                </div>
                <div style="display: flex; justify-content: space-between; flex-wrap: wrap; gap: 10px;">
                    <div>
                        <strong>üë§</strong> {row.get('utilisateur', row.get('user', 'Anonyme'))}
                    </div>
                    <div>
                        <strong>‚≠ê</strong> {rating_display}
                    </div>
                    <div>
                        <strong>üìÖ</strong> {formatted_date}
                    </div>
                </div>
                {f'<div style="margin-top: 10px; font-size: 0.9rem; color: #666;"><strong>üìä Score de sentiment:</strong> {row.get("score_moyen", "N/A"):.2f}</div>' if "score_moyen" in row else ""}
            </div>
            """, unsafe_allow_html=True)
    else:
        # Afficher un message quand aucun avis authentique n'est d√©tect√©
        st.info("""
        **üìä Aucun avis authentique √† afficher**
        
        Cela peut √™tre d√ª √† :
        1. Tous les avis ont √©t√© d√©tect√©s comme suspects
        2. Le seuil de d√©tection est trop bas
        3. Aucune donn√©e valide n'a √©t√© analys√©e
        
        **üí° Conseils :**
        - Ajustez le seuil de d√©tection (actuellement √† {detection_threshold})
        - V√©rifiez la qualit√© des donn√©es
        - Consultez les statistiques de d√©tection
        """.format(detection_threshold=detection_threshold))

# Graphique des faux avis
if fake_count > 0 or real_count > 0:
    fig_fake = px.pie(
        names=["Faux avis", "Avis authentiques"],
        values=[fake_count, real_count],
        title=f"R√©partition des avis (Seuil: {detection_threshold})",
        color=["Faux avis", "Avis authentiques"],
        color_discrete_map={"Faux avis": "#E74C3C", "Avis authentiques": "#2ECC71"},
        hole=0.3
    )
    
    # Ajouter des annotations personnalis√©es
    fig_fake.update_traces(
        textinfo='percent+label',
        textposition='inside',
        hovertemplate="<b>%{label}</b><br>Quantit√©: %{value}<br>Pourcentage: %{percent}"
    )
    
    fig_fake.update_layout(
        annotations=[dict(
            text=f'Total: {len(filtered_df)}',
            x=0.5, y=0.5,
            font_size=20,
            showarrow=False
        )]
    )
    
    st.plotly_chart(fig_fake, use_container_width=True)
else:
    st.warning("‚ö†Ô∏è Aucune donn√©e disponible pour cr√©er le graphique.")

# ================================================================
# ü§ñ CHARGEMENT MOD√àLES IA
# ================================================================
st.subheader("ü§ñ Chargement des mod√®les IA")
models = {
    "youtube": safe_load("model_youtube.sav"),
    "twitter": safe_load("model_tweets.sav"),
    "reviews": safe_load("model_reviews.sav")
}
vectorizers = {
    "youtube": safe_load("youtube_vectorizer.sav"),
    "twitter": safe_load("tweets_vectorizer.sav"),
    "reviews": safe_load("reviews_vectorizer.sav")
}

valid = [k for k in models if models[k] is not None and vectorizers[k] is not None]

if not valid:
    st.warning("‚ö†Ô∏è Aucun mod√®le IA charg√©. Utilisation d'un scoring basique.")
    # Scoring basique bas√© sur les mots positifs/n√©gatifs
    positive_words = ["excellent", "bon", "super", "parfait", "g√©nial", "recommande", "satisfait", 
                      "impressionnant", "puissant", "confortable", "id√©al", "magnifique"]
    negative_words = ["mauvais", "nul", "d√©√ßu", "√©viter", "probl√®me", "m√©diocre", "d√©fectueux",
                      "regrette", "faible", "m√©diocre", "d√©charge", "manque"]
    
    def basic_sentiment_score(text):
        text_lower = text.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)
        
        if pos_count > neg_count:
            return 1, "positive"
        elif neg_count > pos_count:
            return -1, "negative"
        else:
            return 0, "neutral"
    
    filtered_df["score_moyen"] = filtered_df["clean_text"].apply(lambda x: basic_sentiment_score(x)[0])
    filtered_df["sentiment"] = filtered_df["clean_text"].apply(lambda x: basic_sentiment_score(x)[1])
else:
    # ================================================================
    # üì° PR√âDICTIONS IA
    # ================================================================
    pred_cols = []
    for k in valid:
        try:
            X = vectorizers[k].transform(filtered_df["clean_text"])
            filtered_df[f"pred_{k}"] = models[k].predict(X)
            pred_cols.append(f"pred_{k}")
        except Exception as e:
            st.warning(f"Erreur avec le mod√®le {k}: {e}")
            filtered_df[f"pred_{k}"] = np.nan

    label_to_score = {"positive": 1, "neutral": 0, "negative": -1}

    def fusion(row):
        scores = []
        for c in pred_cols:
            v = row[c]
            if pd.notnull(v): scores.append(label_to_score.get(str(v), 0))
        return np.mean(scores) if scores else 0

    filtered_df["score_moyen"] = filtered_df.apply(fusion, axis=1)
    filtered_df["sentiment"] = filtered_df["score_moyen"].apply(lambda s: "positive" if s>0 else "negative" if s<0 else "neutral")

# ================================================================
# üìä CALCUL DES KPI ET SCORES D'ENGAGEMENT
# ================================================================
st.header("üìä KPIs ‚Äì Vue d'ensemble")

# Calcul des scores d'engagement
filtered_df["engagement_score"] = calculate_engagement_score(filtered_df)

# Identifier la colonne produit
product_columns = [col for col in filtered_df.columns if 'product' in col.lower() or 'produit' in col.lower() or 'item' in col.lower()]
product_col = product_columns[0] if product_columns else None

# Statistiques globales
total = len(filtered_df)
pos = (filtered_df["sentiment"]=="positive").sum()
neut = (filtered_df["sentiment"]=="neutral").sum()
neg = (filtered_df["sentiment"]=="negative").sum()

col1, col2, col3, col4, col5, col6 = st.columns(6)
col1.metric("Total messages", total)
col2.metric("Positifs", pos, f"{pos/total:.0%}" if total > 0 else "0%")
col3.metric("Neutres", neut, f"{neut/total:.0%}" if total > 0 else "0%")
col4.metric("N√©gatifs", neg, f"{neg/total:.0%}" if total > 0 else "0%")
col5.metric("Score AIM moyen", f"{filtered_df['score_moyen'].mean():.2f}" if total > 0 else "0.00")
col6.metric("Engagement moyen", f"{filtered_df['engagement_score'].mean():.1f}/5" if total > 0 else "0.0/5")

# ================================================================
# üì¶ ANALYSE PAR PRODUIT (si disponible)
# ================================================================
if product_col and not filtered_df.empty:
    st.header("üì¶ Analyse par Produit")
    
    # KPI par produit
    product_stats = filtered_df.groupby(product_col).agg({
        "sentiment": lambda x: (x == "positive").mean(),
        "score_moyen": "mean",
        "engagement_score": "mean",
        "is_fake": "mean",
        "clean_text": "count"
    }).rename(columns={
        "sentiment": "Taux Positif",
        "score_moyen": "Score Moyen",
        "engagement_score": "Engagement Moyen",
        "is_fake": "Taux Faux Avis",
        "clean_text": "Nombre d'Avis"
    }).round(3)
    
    # Trier par taux positif
    product_stats = product_stats.sort_values("Taux Positif", ascending=False)
    
    st.dataframe(product_stats, use_container_width=True)
    
    # Graphique comparatif
    fig_products = px.bar(
        product_stats.reset_index(),
        x=product_col,
        y=["Taux Positif", "Engagement Moyen"],
        title="Comparaison des produits",
        barmode="group",
        color_discrete_sequence=AIM_PALETTE[:2]
    )
    st.plotly_chart(fig_products, use_container_width=True)

# ================================================================
# üìà GRAPHIQUES ET VISUALISATIONS
# ================================================================

# ------------------ 1Ô∏è‚É£ Top 20 des mots ------------------
st.subheader("üî† Top 20 des mots les plus fr√©quents")

# Ajouter des contr√¥les pour personnaliser l'analyse
with st.expander("‚öôÔ∏è Param√®tres d'analyse", expanded=False):
    col1, col2 = st.columns(2)
    with col1:
        min_word_length = st.slider(
            "Longueur minimale des mots", 
            min_value=2, 
            max_value=8, 
            value=4,
            help="Filtrer les mots trop courts qui sont souvent moins significatifs"
        )
    with col2:
        top_n_words = st.slider(
            "Nombre de mots √† afficher", 
            min_value=10, 
            max_value=50, 
            value=20,
            help="Afficher plus ou moins de mots dans le graphique"
        )

# V√©rifier si filtered_df["clean_text"] contient des donn√©es
if filtered_df["clean_text"].notna().any() and len(filtered_df["clean_text"]) > 0:
    # R√©cup√©rer tout le texte nettoy√©
    all_text = " ".join(filtered_df["clean_text"].dropna().astype(str))
    
    if all_text.strip():  # V√©rifier que le texte n'est pas vide
        # Tokeniser et compter les mots
        all_words = all_text.split()
        
        # Filtrer les mots courts et les stop words AVEC LE PARAM√àTRE DYNAMIQUE
        words = [w for w in all_words if len(w) >= min_word_length and w.lower() not in ENGLISH_STOP_WORDS]
        
        # Compter la fr√©quence
        wc = Counter(words)
        
        if wc:  # V√©rifier que nous avons des mots
            # R√©cup√©rer les N mots les plus fr√©quents (dynamique)
            top_words_list = wc.most_common(top_n_words)
            
            # Cr√©er le DataFrame pour le graphique
            freq_df = pd.DataFrame(top_words_list, columns=["Mot", "Fr√©quence"])
            
            # Cr√©er le graphique √† barres dynamique
            fig_words = px.bar(
                freq_df, 
                x="Mot", 
                y="Fr√©quence",
                title=f"üî† Top {top_n_words} des mots les plus fr√©quents",
                color="Fr√©quence",
                color_continuous_scale=AIM_PALETTE,
                text="Fr√©quence"
            )
            
            # Am√©liorer l'apparence
            fig_words.update_traces(
                textposition='outside',
                marker_line_color='rgb(8,48,107)',
                marker_line_width=1.5
            )
            
            fig_words.update_layout(
                xaxis_tickangle=-45,
                xaxis_title="Mots",
                yaxis_title="Nombre d'occurrences",
                showlegend=False,
                hovermode='x unified'
            )
            
            # Afficher le graphique
            st.plotly_chart(fig_words, use_container_width=True, key="fig_words_top20")
            
            # Statistiques suppl√©mentaires
            st.info(f"""
            **üìä Statistiques d'analyse :**
            - **Mots analys√©s :** {len(words):,} 
            - **Mots uniques :** {len(wc):,}
            - **Longueur minimale :** {min_word_length} caract√®res
            - **Top N affich√© :** {top_n_words} mots
            - **Occurrences totales :** {sum(wc.values()):,}
            """)
            
            # Stocker wc dans session state pour l'utiliser plus tard
            st.session_state.wc = wc
            st.session_state.top_words_list = top_words_list
        else:
            st.warning("‚ö†Ô∏è Aucun mot significatif d√©tect√© apr√®s filtrage.")
            st.session_state.wc = Counter()
            st.session_state.top_words_list = []
    else:
        st.warning("‚ö†Ô∏è Le texte nettoy√© est vide.")
        st.session_state.wc = Counter()
        st.session_state.top_words_list = []
else:
    st.warning("‚ö†Ô∏è Aucun texte disponible pour l'analyse.")
    st.session_state.wc = Counter()
    st.session_state.top_words_list = []

# ------------------ 2Ô∏è‚É£ R√©partition des sentiments ------------------
st.subheader("üìä R√©partition des sentiments")

if not filtered_df.empty and 'sentiment' in filtered_df.columns:
    sentiment_counts = filtered_df['sentiment'].value_counts()
    
    fig_sent = px.pie(
        values=sentiment_counts.values,
        names=sentiment_counts.index,
        title="R√©partition des sentiments",
        color=sentiment_counts.index,
        color_discrete_map={
            "positive": "#2ECC71",
            "neutral": "#F1C40F",
            "negative": "#E74C3C"
        }
    )
    
    # Ajouter des annotations personnalis√©es
    fig_sent.update_traces(
        textinfo='percent+label+value',
        textposition='inside',
        hovertemplate="<b>%{label}</b><br>Quantit√©: %{value}<br>Pourcentage: %{percent}"
    )
    
    st.plotly_chart(fig_sent, use_container_width=True, key="fig_sentiment")
    
    # Statistiques d√©taill√©es
    col1, col2, col3 = st.columns(3)
    with col1:
        positive_pct = (sentiment_counts.get('positive', 0) / len(filtered_df)) * 100
        st.metric("Positifs", f"{sentiment_counts.get('positive', 0):,}", f"{positive_pct:.1f}%")
    with col2:
        neutral_pct = (sentiment_counts.get('neutral', 0) / len(filtered_df)) * 100
        st.metric("Neutres", f"{sentiment_counts.get('neutral', 0):,}", f"{neutral_pct:.1f}%")
    with col3:
        negative_pct = (sentiment_counts.get('negative', 0) / len(filtered_df)) * 100
        st.metric("N√©gatifs", f"{sentiment_counts.get('negative', 0):,}", f"{negative_pct:.1f}%")
    
    st.write("""
    **Objectif :** Ce diagramme circulaire montre la proportion de messages positifs, neutres et n√©gatifs.
    Il donne une vue d'ensemble rapide de la tonalit√© g√©n√©rale des retours clients.
    """)
else:
    st.warning("‚ö†Ô∏è Aucune donn√©e de sentiment disponible.")

# ------------------ 3Ô∏è‚É£ Distribution du score de sentiment ------------------
st.subheader("üìà Distribution du score de sentiment")

if not filtered_df.empty and 'score_moyen' in filtered_df.columns:
    # Cr√©er un histogramme dynamique avec curseur pour le nombre de bins
    col1, col2 = st.columns([3, 1])
    with col2:
        nbins = st.slider("Nombre d'intervalles:", min_value=10, max_value=50, value=30, key="nbins_slider")
    
    # Calculer des statistiques descriptives
    mean_score = filtered_df['score_moyen'].mean()
    median_score = filtered_df['score_moyen'].median()
    std_score = filtered_df['score_moyen'].std()
    
    fig_score = px.histogram(
        filtered_df, 
        x="score_moyen", 
        nbins=nbins,
        title=f"Distribution du score de sentiment ({nbins} intervalles)",
        color_discrete_sequence=AIM_PALETTE,
        labels={"score_moyen": "Score de sentiment", "count": "Nombre d'avis"},
        marginal="box"
    )
    
    # Ajouter des lignes verticales pour les statistiques
    fig_score.add_vline(x=mean_score, line_dash="dash", line_color="red", 
                        annotation_text=f"Moyenne: {mean_score:.2f}", 
                        annotation_position="top right")
    fig_score.add_vline(x=median_score, line_dash="dot", line_color="green", 
                        annotation_text=f"M√©diane: {median_score:.2f}", 
                        annotation_position="top left")
    
    # Ajouter une bo√Æte √† moustaches s√©par√©e
    fig_box = px.box(
        filtered_df,
        y="score_moyen",
        title="Bo√Æte √† moustaches des scores de sentiment",
        color_discrete_sequence=AIM_PALETTE,
        points="all"
    )
    
    # Ajouter des annotations statistiques
    fig_box.add_annotation(
        x=0.5, y=filtered_df['score_moyen'].max(),
        text=f"Moyenne: {mean_score:.2f} | √âcart-type: {std_score:.2f}",
        showarrow=False,
        font=dict(size=12)
    )
    
    tab1, tab2 = st.tabs(["üìä Histogramme + Boxplot", "üì¶ Bo√Æte √† moustaches d√©taill√©e"])
    with tab1:
        st.plotly_chart(fig_score, use_container_width=True)
    with tab2:
        st.plotly_chart(fig_box, use_container_width=True)
    
    # Distribution par sentiment
    st.subheader("üìä Distribution par cat√©gorie de sentiment")
    
    if 'sentiment' in filtered_df.columns:
        fig_sent_dist = px.box(
            filtered_df,
            x="sentiment",
            y="score_moyen",
            color="sentiment",
            color_discrete_map={
                "positive": "#2ECC71",
                "neutral": "#F1C40F",
                "negative": "#E74C3C"
            },
            title="Distribution des scores par sentiment",
            points="all"
        )
        st.plotly_chart(fig_sent_dist, use_container_width=True)
    
    st.write(f"""
    **Objectif :** L'histogramme montre comment les scores de sentiment sont distribu√©s.
    
    **üìä Statistiques descriptives :**
    - **Moyenne :** {mean_score:.3f} (tendance g√©n√©rale)
    - **M√©diane :** {median_score:.3f} (valeur centrale)
    - **√âcart-type :** {std_score:.3f} (dispersion des donn√©es)
    - **Minimum :** {filtered_df['score_moyen'].min():.3f}
    - **Maximum :** {filtered_df['score_moyen'].max():.3f}
    - **√âtendue :** {filtered_df['score_moyen'].max() - filtered_df['score_moyen'].min():.3f}
    
    **üîç Interpr√©tation :**
    - **Scores n√©gatifs (< 0)** : Avis d√©favorables
    - **Scores autour de 0** : Avis neutres  
    - **Scores positifs (> 0)** : Avis favorables
    
    La **ligne rouge pointill√©e** indique la moyenne g√©n√©rale. Une distribution centr√©e √† droite indique une tendance positive, √† gauche une tendance n√©gative.
    """)
else:
    st.warning("‚ö†Ô∏è Aucun score de sentiment disponible pour l'analyse.")

# ------------------ 4Ô∏è‚É£ Statistiques descriptives en fran√ßais ------------------
st.subheader("üìã Statistiques descriptives des scores")

# Calculer les statistiques
if not filtered_df.empty and 'score_moyen' in filtered_df.columns:
    # Statistiques de base
    stats_data = {
        "M√©trique": [
            "Moyenne", "M√©diane", "√âcart-type", "Minimum", 
            "Maximum", "1er Quartile (Q1)", "3√®me Quartile (Q3)", "√âtendue",
            "Intervalle Interquartile", "Coefficient de variation"
        ],
        "Valeur": [
            f"{filtered_df['score_moyen'].mean():.3f}",
            f"{filtered_df['score_moyen'].median():.3f}",
            f"{filtered_df['score_moyen'].std():.3f}",
            f"{filtered_df['score_moyen'].min():.3f}",
            f"{filtered_df['score_moyen'].max():.3f}",
            f"{filtered_df['score_moyen'].quantile(0.25):.3f}",
            f"{filtered_df['score_moyen'].quantile(0.75):.3f}",
            f"{filtered_df['score_moyen'].max() - filtered_df['score_moyen'].min():.3f}",
            f"{filtered_df['score_moyen'].quantile(0.75) - filtered_df['score_moyen'].quantile(0.25):.3f}",
            f"{(filtered_df['score_moyen'].std() / filtered_df['score_moyen'].mean() * 100 if filtered_df['score_moyen'].mean() != 0 else 0):.1f}%"
        ],
        "Interpr√©tation": [
            "Score moyen de tous les avis",
            "Valeur centrale (50% des scores sont inf√©rieurs)",
            "Dispersion des scores autour de la moyenne",
            "Score le plus n√©gatif",
            "Score le plus positif",
            "25% des scores sont inf√©rieurs √† cette valeur",
            "75% des scores sont inf√©rieurs √† cette valeur",
            "Diff√©rence entre les scores extr√™mes",
            "Dispersion des 50% centraux des donn√©es",
            "Variabilit√© relative des scores"
        ]
    }

    stats_df = pd.DataFrame(stats_data)
    
    # Afficher dans un tableau stylis√©
    st.markdown('<div class="statistics-table">', unsafe_allow_html=True)
    
    # Afficher sous forme de m√©triques aussi
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Moyenne", f"{filtered_df['score_moyen'].mean():.3f}")
    with col2:
        st.metric("M√©diane", f"{filtered_df['score_moyen'].median():.3f}")
    with col3:
        st.metric("√âcart-type", f"{filtered_df['score_moyen'].std():.3f}")
    with col4:
        st.metric("√âtendue", f"{filtered_df['score_moyen'].max() - filtered_df['score_moyen'].min():.3f}")
    
    # Tableau d√©taill√©
    st.dataframe(
        stats_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "M√©trique": st.column_config.TextColumn("M√©trique", width="medium"),
            "Valeur": st.column_config.TextColumn("Valeur", width="small"),
            "Interpr√©tation": st.column_config.TextColumn("Interpr√©tation", width="large")
        }
    )
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Analyse de la distribution
    st.subheader("üìä Analyse de la distribution")
    
    # Calculer la skewness et kurtosis
    from scipy.stats import skew, kurtosis
    
    if len(filtered_df) > 1:
        skewness = skew(filtered_df['score_moyen'].dropna())
        kurt = kurtosis(filtered_df['score_moyen'].dropna())
        
        col1, col2 = st.columns(2)
        with col1:
            if skewness > 0.5:
                skew_interpretation = "Asym√©trie positive (queue √† droite)"
                skew_color = "#2ECC71"
            elif skewness < -0.5:
                skew_interpretation = "Asym√©trie n√©gative (queue √† gauche)"
                skew_color = "#E74C3C"
            else:
                skew_interpretation = "Distribution sym√©trique"
                skew_color = "#F1C40F"
            
            st.metric("Asym√©trie (Skewness)", f"{skewness:.3f}", skew_interpretation)
        
        with col2:
            if kurt > 3:
                kurt_interpretation = "Distribution leptokurtique (pic √©lev√©)"
                kurt_color = "#E74C3C"
            elif kurt < 3:
                kurt_interpretation = "Distribution platykurtique (pic bas)"
                kurt_color = "#3498DB"
            else:
                kurt_interpretation = "Distribution normale"
                kurt_color = "#2ECC71"
            
            st.metric("Aplatissement (Kurtosis)", f"{kurt:.3f}", kurt_interpretation)
    
    # Tester la normalit√© avec QQ plot
    st.subheader("üìà Test de normalit√© (QQ Plot)")
    
    try:
        import scipy.stats as stats
        
        # Cr√©er un QQ plot
        fig_qq = go.Figure()
        
        # Calculer les quantiles th√©oriques
        theoretical_quantiles = stats.probplot(filtered_df['score_moyen'].dropna(), dist="norm")
        
        fig_qq.add_trace(go.Scatter(
            x=theoretical_quantiles[0][0],
            y=theoretical_quantiles[0][1],
            mode='markers',
            name='Donn√©es',
            marker=dict(color=AIM_PALETTE[0], size=8)
        ))
        
        # Ajouter la ligne de r√©f√©rence (normale)
        fig_qq.add_trace(go.Scatter(
            x=[theoretical_quantiles[0][0].min(), theoretical_quantiles[0][0].max()],
            y=[theoretical_quantiles[0][0].min() * theoretical_quantiles[1][0] + theoretical_quantiles[1][1],
               theoretical_quantiles[0][0].max() * theoretical_quantiles[1][0] + theoretical_quantiles[1][1]],
            mode='lines',
            name='Loi normale',
            line=dict(color='red', dash='dash')
        ))
        
        fig_qq.update_layout(
            title="QQ Plot - Test de normalit√©",
            xaxis_title="Quantiles th√©oriques (normale)",
            yaxis_title="Quantiles observ√©s",
            showlegend=True
        )
        
        st.plotly_chart(fig_qq, use_container_width=True)
        
        # Interpr√©tation du QQ plot
        st.info("""
        **üîç Interpr√©tation du QQ Plot :**
        - **Points align√©s sur la ligne rouge** : Distribution proche de la normale
        - **Points au-dessus de la ligne en queue droite** : Distribution avec queue lourde √† droite
        - **Points au-dessous de la ligne en queue gauche** : Distribution avec queue lourde √† gauche
        - **Courbure en S** : Distribution avec asym√©trie
        """)
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Impossible de cr√©er le QQ plot : {e}")
else:
    st.warning("‚ö†Ô∏è Aucune statistique disponible pour les scores.")

# ------------------ 5Ô∏è‚É£ Heatmap : influence des mots ------------------
st.subheader("üî• Influence des mots-cl√©s sur le sentiment")

# Utiliser le wc stock√© dans session state
if hasattr(st.session_state, 'wc') and len(st.session_state.wc) > 0:
    wc = st.session_state.wc
    top_words = [w for w, _ in wc.most_common(min(20, len(wc)))]
    
    # Calculer l'influence moyenne de chaque mot
    heat_data = {}
    word_stats = []
    
    for w in top_words:
        # Trouver les avis contenant ce mot
        mask = filtered_df["clean_text"].str.contains(r'\b' + w + r'\b', na=False)
        matching_rows = filtered_df[mask]
        
        if len(matching_rows) > 0:
            avg_score = matching_rows["score_moyen"].mean()
            count = len(matching_rows)
            sentiment_dist = matching_rows["sentiment"].value_counts().to_dict()
            
            heat_data[w] = [avg_score]
            word_stats.append({
                "Mot": w,
                "Fr√©quence": wc[w],
                "Score moyen": avg_score,
                "Occurrences": count,
                "Positifs": sentiment_dist.get('positive', 0),
                "Neutres": sentiment_dist.get('neutral', 0),
                "N√©gatifs": sentiment_dist.get('negative', 0)
            })
        else:
            heat_data[w] = [0]
    
    if heat_data:
        heat_df = pd.DataFrame(heat_data)
        
        fig_heat = px.imshow(
            heat_df,
            labels=dict(x="Mot-cl√©", y="", color="Score moyen"),
            x=heat_df.columns,
            y=["Score moyen"],
            color_continuous_scale="RdYlGn",
            title="üî• Influence des mots-cl√©s sur le sentiment",
            aspect="auto",
            text_auto=".2f"
        )
        
        fig_heat.update_layout(
            xaxis_tickangle=-45,
            height=300
        )
        
        st.plotly_chart(fig_heat, use_container_width=True, key="fig_heatmap")
        
        # Tableau d√©taill√© des mots-cl√©s
        st.subheader("üìã Analyse d√©taill√©e des mots-cl√©s")
        
        if word_stats:
            word_stats_df = pd.DataFrame(word_stats)
            
            # Ajouter des colonnes calcul√©es
            word_stats_df["% Positifs"] = (word_stats_df["Positifs"] / word_stats_df["Occurrences"] * 100).round(1)
            word_stats_df["% N√©gatifs"] = (word_stats_df["N√©gatifs"] / word_stats_df["Occurrences"] * 100).round(1)
            word_stats_df["Impact"] = word_stats_df["Score moyen"].apply(
                lambda x: "üü¢ Positif" if x > 0.1 else "üî¥ N√©gatif" if x < -0.1 else "üü° Neutre"
            )
            
            # Trier par impact
            word_stats_df = word_stats_df.sort_values("Score moyen", ascending=False)
            
            # Afficher le tableau
            st.dataframe(
                word_stats_df,
                use_container_width=True,
                column_config={
                    "Mot": st.column_config.TextColumn("Mot-cl√©"),
                    "Fr√©quence": st.column_config.NumberColumn("Fr√©q. totale", format="%d"),
                    "Score moyen": st.column_config.NumberColumn("Score moyen", format="%.3f"),
                    "Occurrences": st.column_config.NumberColumn("Occurrences", format="%d"),
                    "% Positifs": st.column_config.NumberColumn("% Pos", format="%.1f%%"),
                    "% N√©gatifs": st.column_config.NumberColumn("% N√©g", format="%.1f%%"),
                    "Impact": st.column_config.TextColumn("Impact")
                }
            )
        
        st.write("""
        **Objectif :** Cette heatmap montre l'influence moyenne de chaque mot-cl√© sur le sentiment.
        
        **üé® L√©gende des couleurs :**
        - **üü¢ Vert fonc√©** : Impact fortement positif (score > 0.5)
        - **üü¢ Vert clair** : Impact positif mod√©r√© (0 < score ‚â§ 0.5)
        - **üü° Jaune** : Impact neutre (score ‚âà 0)
        - **üî¥ Rouge clair** : Impact n√©gatif mod√©r√© (-0.5 ‚â§ score < 0)
        - **üî¥ Rouge fonc√©** : Impact fortement n√©gatif (score < -0.5)
        
        **üí° Insights actionnables :**
        1. **Mots positifs** : √Ä int√©grer dans vos communications marketing
        2. **Mots n√©gatifs** : √Ä surveiller et adresser dans vos am√©liorations
        3. **Mots fr√©quents** : Refl√®tent les pr√©occupations principales des clients
        """)
        
        # Graphique suppl√©mentaire : Mots les plus positifs/n√©gatifs
        st.subheader("üìä Mots les plus influents sur le sentiment")
        
        if word_stats:
            # Top 10 mots positifs
            positive_words = word_stats_df[word_stats_df["Score moyen"] > 0].head(10)
            # Top 10 mots n√©gatifs
            negative_words = word_stats_df[word_stats_df["Score moyen"] < 0].head(10)
            
            if not positive_words.empty:
                fig_pos = px.bar(
                    positive_words,
                    x="Mot",
                    y="Score moyen",
                    title="üîù Top 10 des mots les plus positifs",
                    color="Score moyen",
                    color_continuous_scale="Greens",
                    text="Score moyen"
                )
                fig_pos.update_traces(texttemplate='%{text:.3f}', textposition='outside')
                st.plotly_chart(fig_pos, use_container_width=True)
            
            if not negative_words.empty:
                fig_neg = px.bar(
                    negative_words,
                    x="Mot",
                    y="Score moyen",
                    title="‚ö†Ô∏è Top 10 des mots les plus n√©gatifs",
                    color="Score moyen",
                    color_continuous_scale="Reds",
                    text="Score moyen"
                )
                fig_neg.update_traces(texttemplate='%{text:.3f}', textposition='outside')
                st.plotly_chart(fig_neg, use_container_width=True)
    else:
        st.warning("‚ö†Ô∏è Donn√©es insuffisantes pour cr√©er la heatmap.")
else:
    st.warning("‚ö†Ô∏è Aucun mot-cl√© disponible pour l'analyse d'influence.")

# ================================================================
# üé™ OPPORTUNIT√âS MARKETING DYNAMIQUES
# ================================================================
st.write("---")
st.header("üé™ Opportunit√©s Marketing D√©tect√©es")

# V√©rifier si wc existe dans session state
if hasattr(st.session_state, 'wc') and len(st.session_state.wc) > 0:
    wc = st.session_state.wc
    
    # Param√®tres configurables pour les opportunit√©s
    with st.expander("‚öôÔ∏è Param√®tres des opportunit√©s", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            num_opportunities = st.slider(
                "Nombre d'opportunit√©s √† afficher",
                min_value=5,
                max_value=30,
                value=15,
                help="Choisissez le nombre d'opportunit√©s marketing √† analyser"
            )
        with col2:
            min_frequency = st.slider(
                "Fr√©quence minimale",
                min_value=1,
                max_value=10,
                value=2,
                help="Filtrez les mots trop peu fr√©quents"
            )
    
    # Filtrer les mots par fr√©quence minimale
    filtered_words = {word: freq for word, freq in wc.items() if freq >= min_frequency}
    
    if filtered_words:
        # Trier par fr√©quence
        top_words = Counter(filtered_words).most_common(num_opportunities)
        total_words_count = sum(filtered_words.values())
        
        # Calculer l'impact sentiment pour chaque mot
        word_opportunities = []
        for mot, freq in top_words:
            # Calculer le score sentiment moyen pour ce mot
            mask = filtered_df["clean_text"].str.contains(r'\b' + mot + r'\b', na=False)
            matching_rows = filtered_df[mask]
            
            if len(matching_rows) > 0:
                avg_score = matching_rows["score_moyen"].mean()
                sentiment_dist = matching_rows["sentiment"].value_counts().to_dict()
                positive_pct = (sentiment_dist.get('positive', 0) / len(matching_rows)) * 100
            else:
                avg_score = 0
                positive_pct = 0
            
            freq_percentage = (freq / total_words_count) * 100
            
            # D√©terminer le type d'opportunit√©
            if freq_percentage > 5:
                opp_type = "üî• Hot Trend"
                opp_color = "#FF5722"
                opp_icon = "üî•"
            elif freq_percentage > 2:
                opp_type = "üìà Opportunity"
                opp_color = "#FF9800"
                opp_icon = "üìà"
            elif positive_pct > 70:
                opp_type = "üíé Gemme Positive"
                opp_color = "#4CAF50"
                opp_icon = "üíé"
            elif positive_pct > 50:
                opp_type = "üí° Emerging"
                opp_color = "#2196F3"
                opp_icon = "üí°"
            else:
                opp_type = "üîç Niche"
                opp_color = "#9C27B0"
                opp_icon = "üîç"
            
            word_opportunities.append({
                "mot": mot,
                "freq": freq,
                "freq_percentage": freq_percentage,
                "avg_score": avg_score,
                "positive_pct": positive_pct,
                "opp_type": opp_type,
                "opp_color": opp_color,
                "opp_icon": opp_icon
            })
        
        # Trier par pertinence (combinaison fr√©quence et positivit√©)
        word_opportunities.sort(
            key=lambda x: (x['freq_percentage'] * 0.6 + x['positive_pct'] * 0.4), 
            reverse=True
        )
        
        # Afficher les opportunit√©s en grille
        st.subheader(f"üîù Top {len(word_opportunities)} Opportunit√©s Marketing")
    
        
        # Graphique des opportunit√©s par cat√©gorie
        st.subheader("üìä R√©partition des opportunit√©s par cat√©gorie")
        
        # Compter les opportunit√©s par type
        opp_counts = {}
        for opp in word_opportunities:
            opp_type = opp['opp_type'].split()[-1]  # Prendre le dernier mot
            opp_counts[opp_type] = opp_counts.get(opp_type, 0) + 1
        
        if opp_counts:
            fig_opp_cat = px.pie(
                values=list(opp_counts.values()),
                names=list(opp_counts.keys()),
                title="R√©partition des types d'opportunit√©s",
                color_discrete_sequence=AIM_PALETTE
            )
            st.plotly_chart(fig_opp_cat, use_container_width=True)
        
        # Graphique Treemap des opportunit√©s
        st.subheader("üó∫Ô∏è Carte des opportunit√©s marketing")
        
        opp_df = pd.DataFrame(word_opportunities)
        
        fig_opp_treemap = px.treemap(
            opp_df,
            path=["opp_type", "mot"],
            values="freq",
            title="üó∫Ô∏è Carte des opportunit√©s marketing par importance",
            color="positive_pct",
            color_continuous_scale="YlOrRd",
            hover_data=["freq", "freq_percentage", "avg_score", "positive_pct"]
        )
        
        fig_opp_treemap.update_traces(
            textinfo="label+value",
            texttemplate="<b>%{label}</b><br>%{value} occ."
        )
        
        st.plotly_chart(fig_opp_treemap, use_container_width=True)
        
        # Recommandations synth√©tiques bas√©es sur les opportunit√©s
        st.subheader("üéØ Recommandations strat√©giques bas√©es sur les opportunit√©s")
        
        # Analyser les tendances
        high_freq_words = [opp for opp in word_opportunities if opp['freq_percentage'] > 3]
        high_positive_words = [opp for opp in word_opportunities if opp['positive_pct'] > 80]
        high_negative_words = [opp for opp in word_opportunities if opp['avg_score'] < -0.2]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if high_freq_words:
                st.info(f"""
                **üìà Tendances dominantes ({len(high_freq_words)})**
                - Mots les plus fr√©quemment utilis√©s
                - Refl√®tent les sujets principaux
                - Opportunit√© de capitalisation
                """)
        
        with col2:
            if high_positive_words:
                st.success(f"""
                **üíé Points forts ({len(high_positive_words)})**
                - Mots associ√©s √† des retours tr√®s positifs
                - Arguments marketing puissants
                - Atouts √† mettre en avant
                """)
        
        with col3:
            if high_negative_words:
                st.warning(f"""
                **‚ö†Ô∏è Points de vigilance ({len(high_negative_words)})**
                - Mots associ√©s √† des retours n√©gatifs
                - Zones d'am√©lioration prioritaires
                - N√©cessitent une attention particuli√®re
                """)
        
        # Recommandations d√©taill√©es
        st.info("""
        **üìã Synth√®se des Opportunit√©s Marketing :**
        
        **üéØ Strat√©gie recommand√©e :**
        1. **Capitaliser sur les mots positifs fr√©quents** : Int√©grez-les dans vos campagnes
        2. **Adresser les pr√©occupations communes** : Travaillez sur les points n√©gatifs r√©currents
        3. **Surveiller les tendances √©mergentes** : Les mots en croissance sont des indicateurs pr√©coces
        4. **Personnaliser le contenu** : Adaptez vos messages aux mots-cl√©s identifi√©s
        
        **üìä M√©triques cl√©s de succ√®s :**
        - **Engagement** : Augmentation des interactions avec le contenu cibl√©
        - **Sentiment** : Am√©lioration du score moyen des retours
        - **Conversion** : Taux de conversion sur les campagnes optimis√©es
        - **R√©putation** : R√©duction des mentions n√©gatives sur les points adress√©s
        """)
        
        # T√©l√©charger les opportunit√©s
        st.download_button(
            label="üì• T√©l√©charger le rapport d'opportunit√©s",
            data=pd.DataFrame(word_opportunities).to_csv(index=False, encoding='utf-8-sig'),
            file_name="opportunites_marketing_aim.csv",
            mime="text/csv"
        )
    else:
        st.warning(f"""
        ‚ö†Ô∏è **Aucune opportunit√© ne correspond aux crit√®res**
        
        **Raisons possibles :**
        1. Fr√©quence minimale trop √©lev√©e (actuellement : {min_frequency})
        2. Donn√©es textuelles insuffisantes
        3. Texte trop diversifi√© sans mots r√©currents
        
        **Suggestions :**
        - R√©duisez la fr√©quence minimale
        - Augmentez le volume de donn√©es
        - V√©rifiez la qualit√© du texte nettoy√©
        """)
else:
    st.warning("""
    ‚ö†Ô∏è **Aucune opportunit√© marketing d√©tect√©e**
    
    **Causes possibles :**
    1. Aucune donn√©e texte disponible
    2. Texte nettoy√© vide ou insuffisant
    3. Probl√®me d'analyse des mots-cl√©s
    
    **Solutions :**
    - V√©rifiez que votre dataset contient du texte
    - Assurez-vous que le pr√©traitement a fonctionn√©
    - Chargez plus de donn√©es pour une analyse significative
    """)